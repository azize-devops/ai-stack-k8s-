{"instruction": "What is a Kubernetes Pod?", "input": "", "output": "A Pod is the smallest deployable unit in Kubernetes. It represents a single instance of a running process and can contain one or more tightly coupled containers that share the same network namespace, IP address, and storage volumes. Pods are ephemeral by nature and are typically managed by higher-level controllers like Deployments or StatefulSets rather than being created directly."}
{"instruction": "Explain the difference between a Deployment and a StatefulSet in Kubernetes.", "input": "", "output": "A Deployment manages stateless application replicas where each Pod is interchangeable and can be replaced freely. Pods get random names and can be scaled up or down without concern for ordering. A StatefulSet, on the other hand, manages stateful applications where each Pod has a stable hostname, persistent storage, and ordered deployment and scaling. StatefulSet Pods are created sequentially (pod-0, pod-1, pod-2) and terminated in reverse order, which is essential for databases and clustered applications."}
{"instruction": "How do you create a Kubernetes namespace?", "input": "", "output": "You can create a namespace imperatively with 'kubectl create namespace my-namespace' or declaratively by applying a YAML manifest: apiVersion v1, kind Namespace, metadata with name set to my-namespace. Namespaces provide logical isolation for resources within a cluster and are commonly used to separate environments (dev, staging, production) or teams."}
{"instruction": "What is a Kubernetes Service and what types are available?", "input": "", "output": "A Kubernetes Service is an abstraction that defines a logical set of Pods and a policy for accessing them, providing a stable network endpoint. There are four types: ClusterIP (default) exposes the service on an internal cluster IP; NodePort exposes it on each node's IP at a static port; LoadBalancer provisions an external load balancer from the cloud provider; and ExternalName maps the service to a DNS name. Services use label selectors to discover backend Pods."}
{"instruction": "What is a ConfigMap and how is it used?", "input": "", "output": "A ConfigMap is a Kubernetes object used to store non-confidential configuration data as key-value pairs. It decouples configuration from container images, making applications portable. ConfigMaps can be consumed by Pods as environment variables, command-line arguments, or as configuration files mounted in a volume. They are created using 'kubectl create configmap' or from YAML manifests and can hold entire configuration files or individual settings."}
{"instruction": "How does a Kubernetes Secret differ from a ConfigMap?", "input": "", "output": "While both ConfigMaps and Secrets store key-value data, Secrets are specifically designed for sensitive information like passwords, tokens, and TLS certificates. Secret values are base64-encoded (not encrypted by default) and Kubernetes provides additional protections: they are stored in tmpfs on nodes rather than disk, access can be restricted via RBAC, and they can be encrypted at rest when etcd encryption is configured. For true security, consider integrating external secret managers like HashiCorp Vault."}
{"instruction": "Explain what a PersistentVolume and PersistentVolumeClaim are.", "input": "", "output": "A PersistentVolume (PV) is a piece of storage in the cluster provisioned by an administrator or dynamically via a StorageClass. It exists independently of any Pod. A PersistentVolumeClaim (PVC) is a request for storage by a user, specifying size and access modes. When a PVC is created, Kubernetes binds it to a suitable PV. This abstraction separates storage provisioning from consumption, allowing Pods to use persistent storage without knowing the underlying infrastructure details."}
{"instruction": "What is a DaemonSet and when would you use one?", "input": "", "output": "A DaemonSet ensures that a copy of a specific Pod runs on all (or a subset of) nodes in a cluster. When new nodes are added, the DaemonSet automatically schedules the Pod on them. Common use cases include running log collectors like Fluentd or Filebeat on every node, deploying monitoring agents such as Prometheus Node Exporter, running network plugins or storage daemons, and managing node-level security agents. You can use node selectors or tolerations to restrict which nodes run the DaemonSet Pods."}
{"instruction": "How do you perform a rolling update for a Deployment?", "input": "", "output": "Rolling updates are the default strategy for Kubernetes Deployments. To trigger one, update the container image with 'kubectl set image deployment/my-app container-name=new-image:tag' or edit the Deployment YAML and apply it. Kubernetes gradually replaces old Pods with new ones, controlled by maxUnavailable (how many Pods can be down during the update) and maxSurge (how many extra Pods can exist). Monitor progress with 'kubectl rollout status deployment/my-app' and roll back with 'kubectl rollout undo deployment/my-app' if issues arise."}
{"instruction": "What are init containers in Kubernetes?", "input": "", "output": "Init containers are specialized containers that run to completion before any application containers start in a Pod. They run sequentially, and each must complete successfully before the next one begins. Common use cases include waiting for a dependency service to become available, performing database migrations, downloading configuration files or secrets from external sources, and setting up file permissions on shared volumes. Init containers have access to the same volumes as app containers but can use different images and tools."}
{"instruction": "Explain Kubernetes liveness, readiness, and startup probes.", "input": "", "output": "Kubernetes supports three types of health probes. Liveness probes detect when a container is stuck or deadlocked and trigger a restart. Readiness probes determine when a container is ready to accept traffic, controlling whether it receives requests from a Service. Startup probes are used for slow-starting containers, disabling liveness and readiness checks until the application has started. Each probe can use HTTP GET requests, TCP socket connections, or command execution. Proper probe configuration prevents traffic from reaching unhealthy Pods and enables automatic recovery."}
{"instruction": "What is Helm and why is it used with Kubernetes?", "input": "", "output": "Helm is the package manager for Kubernetes. It uses charts, which are collections of templated YAML manifests, to define, install, and upgrade applications. Helm solves several problems: it packages complex multi-resource applications into a single deployable unit, supports parameterisation through values files so the same chart works across environments, manages release versioning and rollbacks, and handles dependency management between charts. The Helm CLI interacts with the Kubernetes API to install and manage releases."}
{"instruction": "How does Kubernetes handle DNS resolution?", "input": "", "output": "Kubernetes runs a cluster DNS service (typically CoreDNS) that automatically creates DNS records for Services and Pods. Services get A records in the format service-name.namespace.svc.cluster.local. Headless Services (clusterIP: None) create A records for each backing Pod. Pods can resolve services in the same namespace using just the service name, or use the full FQDN for cross-namespace resolution. CoreDNS configuration can be customized through its ConfigMap for features like custom upstream resolvers, rewrites, or caching policies."}
{"instruction": "What is a Kubernetes Ingress and how does it work?", "input": "", "output": "An Ingress is a Kubernetes resource that manages external HTTP and HTTPS access to services within a cluster. It provides URL-based routing, SSL/TLS termination, name-based virtual hosting, and load balancing. An Ingress resource defines the routing rules, but it requires an Ingress Controller (such as NGINX Ingress Controller, Traefik, or HAProxy) to actually implement them. The controller watches for Ingress resources and configures the underlying proxy accordingly. Modern alternatives include the Gateway API, which provides more expressive routing capabilities."}
{"instruction": "Explain how resource requests and limits work in Kubernetes.", "input": "", "output": "Resource requests and limits control how much CPU and memory a container can use. Requests define the minimum resources guaranteed to the container and are used by the scheduler to find a suitable node. Limits define the maximum resources a container can consume. If a container exceeds its memory limit, it is OOM-killed. If it exceeds its CPU limit, it is throttled. Best practice is to always set requests equal to or less than limits. Quality of Service classes (Guaranteed, Burstable, BestEffort) are assigned based on how requests and limits are configured."}
{"instruction": "What is GitOps and how does it relate to Kubernetes?", "input": "", "output": "GitOps is an operational framework where Git repositories serve as the single source of truth for declarative infrastructure and application configuration. In Kubernetes, GitOps tools like ArgoCD or Flux continuously monitor a Git repository and automatically reconcile the cluster state to match the desired state defined in the repo. Benefits include auditable change history through Git commits, easy rollbacks by reverting commits, consistent environments, and reduced manual intervention. Pull-based GitOps (where the agent pulls changes) is preferred over push-based approaches for security."}
{"instruction": "How do you debug a Pod that is in CrashLoopBackOff status?", "input": "", "output": "CrashLoopBackOff means the container keeps crashing and Kubernetes is backing off on restart attempts. To debug: first run 'kubectl describe pod pod-name' to check events and the exit code. Then check logs with 'kubectl logs pod-name' or 'kubectl logs pod-name --previous' for the last crashed instance. Common causes include application errors, missing configuration or secrets, insufficient resources, failed health probes, or incorrect command/entrypoint. If logs are insufficient, try running the container image locally with Docker or use 'kubectl debug' to attach an ephemeral debug container."}
{"instruction": "What is a Kubernetes Operator and when should you build one?", "input": "", "output": "A Kubernetes Operator is a method of packaging, deploying, and managing an application using custom resources and custom controllers. It extends the Kubernetes API with domain-specific knowledge about how to deploy, scale, backup, and recover a specific application. You should consider building an Operator when your application requires complex lifecycle management beyond what standard controllers provide, such as automated backups, failover handling, or multi-step provisioning. Frameworks like Operator SDK, Kubebuilder, and Metacontroller simplify Operator development."}
{"instruction": "Explain the concept of taints and tolerations in Kubernetes.", "input": "", "output": "Taints are applied to nodes to repel Pods that do not tolerate them, while tolerations are applied to Pods to allow scheduling on tainted nodes. A taint has a key, value, and effect (NoSchedule, PreferNoSchedule, or NoExecute). NoSchedule prevents new Pods from scheduling; PreferNoSchedule is a soft version; NoExecute evicts running Pods that lack the toleration. Common uses include dedicating nodes for specific workloads (GPU nodes for ML jobs), keeping certain nodes free from regular workloads, and managing node conditions like disk pressure."}
{"instruction": "What is a container runtime and which ones does Kubernetes support?", "input": "", "output": "A container runtime is the software responsible for running containers on a node. Kubernetes communicates with runtimes through the Container Runtime Interface (CRI). The most common runtimes are containerd (the default in most distributions, lightweight and production-proven), CRI-O (designed specifically for Kubernetes, popular in OpenShift), and gVisor or Kata Containers for enhanced isolation. Docker was previously the default but its built-in CRI shim (dockershim) was removed in Kubernetes 1.24. Most Docker-built images continue to work because they follow the OCI standard."}
{"instruction": "How do you implement network policies in Kubernetes?", "input": "", "output": "NetworkPolicies are Kubernetes resources that control traffic flow between Pods at the IP and port level. By default, all Pods can communicate freely. Once you apply a NetworkPolicy selecting certain Pods, only explicitly allowed traffic is permitted. Policies specify ingress (incoming) and egress (outgoing) rules using Pod selectors, namespace selectors, and IP blocks. A CNI plugin that supports NetworkPolicy (such as Calico, Cilium, or Weave Net) must be installed for policies to take effect. Start with a default-deny policy and then whitelist required communication paths."}
{"instruction": "What is Infrastructure as Code and why is it important for DevOps?", "input": "", "output": "Infrastructure as Code (IaC) is the practice of managing and provisioning infrastructure through machine-readable configuration files rather than manual processes. Tools like Terraform, Pulumi, and CloudFormation allow you to define servers, networks, and services declaratively. IaC is essential for DevOps because it enables version control of infrastructure changes, reproducible environments, automated provisioning, easy disaster recovery, and consistent configuration across development, staging, and production. It eliminates configuration drift and makes infrastructure changes auditable and reviewable through code review processes."}
{"instruction": "Explain the purpose of a CI/CD pipeline in DevOps.", "input": "", "output": "A CI/CD pipeline automates the process of building, testing, and deploying software. Continuous Integration (CI) involves automatically building and testing code changes whenever developers push to a shared repository, catching integration issues early. Continuous Delivery (CD) extends this by automatically preparing releases for deployment, while Continuous Deployment goes further by automatically deploying to production. Pipeline stages typically include code linting, unit tests, integration tests, container image building, security scanning, staging deployment, and production rollout. Tools include Jenkins, GitLab CI, GitHub Actions, and ArgoCD."}
{"instruction": "How does Kubernetes horizontal pod autoscaling work?", "input": "", "output": "The Horizontal Pod Autoscaler (HPA) automatically adjusts the number of Pod replicas in a Deployment, ReplicaSet, or StatefulSet based on observed metrics. By default, it scales based on CPU utilization, but it can also use memory or custom metrics via the metrics API. The HPA controller runs a control loop (default every 15 seconds) that computes the desired replica count using the formula: desired = ceil(current * (currentMetric / targetMetric)). It respects minReplicas and maxReplicas bounds. Configure it with 'kubectl autoscale' or a HorizontalPodAutoscaler YAML manifest. The Metrics Server must be installed for resource-based autoscaling."}
{"instruction": "What are Kubernetes labels and annotations, and how do they differ?", "input": "", "output": "Labels are key-value pairs attached to Kubernetes objects used for identification and selection. They are queryable via label selectors and are used by Services, Deployments, and other controllers to find and group resources. Annotations are also key-value pairs but are intended for non-identifying metadata such as build information, tool configuration, or human-readable descriptions. Unlike labels, annotations cannot be used in selectors. Labels should be short and structured for querying, while annotations can hold larger, arbitrary data. Both are stored in the metadata section of resource manifests."}
